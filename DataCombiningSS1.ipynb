{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependancies\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "import re\n",
    "import numpy as np\n",
    "import us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting variables\n",
    "startpath =\"_Star_Ratings_and_Display_Measures/\" #start of star rating path\n",
    "fallpath =\"_Star_Ratings_Fall_Release/\"#path for fall ratings\n",
    "cpath=\"_Part_C\"#path for part c data\n",
    "dpath=\"_Part_D\"#path for part d data\n",
    "finalpath =\"_Report_Card_Master_Table.xlsx\"#last part of star rating path\n",
    "firstfive = [\"Contract Number\",\"Organization Type\",\"Contract Name\",\"Organization Marketing Name\",\"Parent Organization\"]#name of first five columns\n",
    "lasttwo =[\"Year\",\"Overall\"] #name of what will be final 2 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get measure star information\n",
    "#takes in path of the file\n",
    "#returns dataframe of the star information\n",
    "def get_measure_stars(path):\n",
    "    dfms = pd.read_excel(path,\"Measure_Stars\",header=2)#df of the raw information\n",
    "    dfms = dfms.iloc[1:]#remove first line of data\n",
    "    #loop through the columns after the first five\n",
    "    for x in range(5,len(dfms.keys())):\n",
    "        #remove letter number information from column name\n",
    "        dfms =dfms.rename(columns= {dfms.keys()[x] : re.split(r'\\d+:',dfms.keys()[x])[0]+re.split(r'\\d+:',dfms.keys()[x])[1]})\n",
    "    #loop through the first 5 columns to give them proper names\n",
    "    for x in range(5):\n",
    "        #rename the columns\n",
    "        dfms = dfms.rename(columns={f\"Unnamed: {x}\":firstfive[x]})\n",
    "    #return the data frame\n",
    "    return dfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get Domain star information\n",
    "#takes in path of the file\n",
    "#returns dataframe of the star information\n",
    "def get_domain_stars(path):\n",
    "    dfds = pd.read_excel(path,\"Domain_Stars\",header=1)\n",
    "    return dfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get summary star information\n",
    "#takes in path of the file\n",
    "#returns dataframe of the star information\n",
    "def get_summary_rating(path):\n",
    "    #read in data frame\n",
    "    dfsr = pd.read_excel(path,\"Summary_Rating\",header=1)\n",
    "    #remove the sanction deduction column\n",
    "    dfsr = dfsr.drop(columns=\"Sanction Deduction\",errors='ignore')\n",
    "    #retrun dataframe\n",
    "    return dfsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to combine the 3 dataframes and do basic cleanup on them used for early years\n",
    "#takes year of the function\n",
    "#returns the cleaned dataframe\n",
    "def get_early(y):\n",
    "    #build path for files\n",
    "    fullpath = f\"./Data/{y}{startpath}{y}{fallpath}{y}{finalpath}\"\n",
    "    #get measure stars info\n",
    "    dfmsf = get_measure_stars(fullpath)\n",
    "    #get domain star info\n",
    "    dfdsf = get_domain_stars(fullpath)\n",
    "    #get summary star info\n",
    "    dfsrf = get_summary_rating(fullpath)\n",
    "    #merge measure and domain stars\n",
    "    dff = pd.merge(dfmsf,dfdsf,on=firstfive,how='left')\n",
    "    #merge measure, domain, and summary star dataframes\n",
    "    dff = pd.merge(dff,dfsrf,on=firstfive,how='left')\n",
    "    #add year column\n",
    "    dff[\"Year\"] = f\"{y}\"\n",
    "    #rename columns\n",
    "    dff = dff.rename(columns={f\"{y} Part C Summary\":\"Part C Summary\",f\"{y} Overall\":\"Overall\",f\"{y} Part D Summary\":\"Part D Summary\"})\n",
    "    #drop unneeded columns\n",
    "    dff = dff.drop(columns = \"2017 Disaster %\",errors='ignore')\n",
    "    #return dataframe\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to combine the 3 dataframes and do basic cleanup on them used for later years\n",
    "#takes year of the function\n",
    "#returns the cleaned dataframe\n",
    "def get_late(y):\n",
    "    #build path for files\n",
    "    fullpath = f\"./Data/{y}{startpath}{y}{finalpath}\"\n",
    "    #get measure stars info\n",
    "    dfmsc = get_measure_stars(fullpath)\n",
    "    #get domain star info\n",
    "    dfdsc = get_domain_stars(fullpath)\n",
    "    #get summary star info\n",
    "    dfsrc = get_summary_rating(fullpath)\n",
    "    #drop disaster columns\n",
    "    dfsrc = dfsrc.drop(columns=dfsrc.columns[[6,7]],axis = 1)\n",
    "    #merge measure and domain stars\n",
    "    df = pd.merge(dfmsc,dfdsc,on=firstfive,how='left')\n",
    "    #merge measure, domain, and summary star dataframes\n",
    "    df = pd.merge(df,dfsrc,on=firstfive,how='left')\n",
    "    #rename columns\n",
    "    df = df.rename(columns={f\"{y} Part C Summary\":\"Part C Summary\",f\"{y} Overall\":\"Overall\",f\"{y} Part D Summary\":\"Part D Summary\"})\n",
    "    #add year column\n",
    "    df[\"Year\"] = f\"{y}\"\n",
    "    #return dataframe\n",
    "    return    df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to combine the dataframse for all of the years\n",
    "#no input\n",
    "#returns data frame with data from all years\n",
    "def standardize_data():\n",
    "    #set first year\n",
    "    year = 2014\n",
    "    #set years of data\n",
    "    years = [x for x in range(2015,2026)]\n",
    "    #set path for part C 2014        \n",
    "    fullpath = f\"./Data/{year}{startpath}{year}{fallpath}{year}{cpath}{finalpath}\"\n",
    "    #get measure star dataframe for part C 2014\n",
    "    dfmsc = get_measure_stars(fullpath)\n",
    "    #get domain star dataframe for part C 2014\n",
    "    dfdsc = get_domain_stars(fullpath)\n",
    "    #get summary star dataframe for part C 2014\n",
    "    dfsrc = get_summary_rating(fullpath)\n",
    "    #merge measure and domain star dataframes for part C 2014\n",
    "    df = pd.merge(dfmsc,dfdsc,on=firstfive,how='left')\n",
    "    #merge measure, domain, and summary star dataframes for part C 2014\n",
    "    df = pd.merge(df,dfsrc,on=firstfive,how='left')\n",
    "    #set path for part D 2014    \n",
    "    fullpath = f\"./Data/{year}{startpath}{year}{fallpath}{year}{dpath}{finalpath}\"\n",
    "    #get measure star dataframe for part D 2014\n",
    "    dfmsd = get_measure_stars(fullpath)\n",
    "    #get domain star dataframe for part D 2014\n",
    "    dfdsd = get_domain_stars(fullpath)\n",
    "    #get summary star dataframe for part D 2014\n",
    "    dfsrd = get_summary_rating(fullpath)\n",
    "    #merge measure and domain star dataframes for part D 2014\n",
    "    dfd = pd.merge(dfmsd,dfdsd,on=['Contract Number'],how='left')\n",
    "    #merge measure, domain, and summary star dataframes for part D 2014\n",
    "    dfd = pd.merge(dfd,dfsrd,on=['Contract Number'],how='left')\n",
    "    #drop duplicate columns\n",
    "    dfd = dfd.drop(columns=[\"Organization Type_x\",\"Contract Name_x\",\"Organization Marketing Name_x\",\"Parent Organization_x\",\"Organization Type_y\",\"Contract Name_y\",\"Organization Marketing Name_y\",\"Parent Organization_y\"])\n",
    "    #merge part C and D data\n",
    "    df = pd.merge(df,dfd,on=[\"Contract Number\",\"Organization Type\",\"Contract Name\",\"Organization Marketing Name\",\"Parent Organization\",\"SNP\"],how='left')\n",
    "    #rename columns\n",
    "    df = df.rename(columns={f\"{year} Part C Summary Rating\":\"Part C Summary\",f\"{year} Overall Rating\":\"Overall\",f\"{year} Part D Summary Rating\":\"Part D Summary\"})\n",
    "    #add year to  dataframes\n",
    "    df[\"Year\"] = \"2014\"\n",
    "    finaldf = df\n",
    "    #loop through years\n",
    "    for year in years:\n",
    "        #choose which merger to call if early call early otherwise call late\n",
    "        if (year <2020):\n",
    "            df = get_early(year)\n",
    "        else:\n",
    "            df = get_late(year)\n",
    "        #concatinate the dataframes into one big data frame\n",
    "        newdf = pd.concat([finaldf,df],axis=0,join='outer')\n",
    "        #change the dataframe so it can be reused\n",
    "        finaldf=newdf\n",
    "    #reset index of dataframe    \n",
    "    finaldf = finaldf.reset_index(drop=True)\n",
    "    #return final dataframe\n",
    "    return finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean the dataframe\n",
    "#takes in a dataframe\n",
    "#returns cleaned dataframe\n",
    "def clean_data(combodf1):\n",
    "    #loop through columns in dataframe\n",
    "    for x in range(len(combodf1.keys())):\n",
    "        #change datatypes to string\n",
    "        combodf1[combodf1.keys()[x]] = combodf1[combodf1.keys()[x]].astype(str)\n",
    "    #trim various typs of data to remove excess spaces\n",
    "    combodf1 = combodf1.replace('\\\\s*Plan\\\\s*too\\\\s*new\\\\s*to\\\\s*be\\\\s*measured\\\\s*','Plan too new to be measured',regex=True)\n",
    "    combodf1 = combodf1.replace('\\\\s*Plan\\\\s*too\\\\s*small\\\\s*to\\\\s*be\\\\s*measured\\\\s*','Plan too small to be measured',regex=True)\n",
    "    combodf1 = combodf1.replace('\\\\s*Plan\\\\s*not\\\\s*required\\\\s*to\\\\s*report\\\\s*measure\\\\s*','Plan not required to report measure',regex=True)\n",
    "    combodf1 = combodf1.replace('\\\\s*No\\\\s*data\\\\s*available\\\\s*','No data available',regex=True)\n",
    "    combodf1 = combodf1.replace('Nodata available','No data available',regex=True)\n",
    "    combodf1 = combodf1.replace('\\\\s*Not\\\\s*enough\\\\s*data\\\\s*available\\\\s*','Not enough data available',regex=True)\n",
    "    combodf1 = combodf1.replace('\\\\s*Benefit\\\\s*not\\\\s*offered\\\\s*by\\\\s*plan\\\\s*','Benefit not offered by plan',regex=True)\n",
    "    #change yes and not to true and false\n",
    "    combodf1 = combodf1.replace('\\\\s*Yes\\\\s*',True,regex=True)    \n",
    "    combodf1 = combodf1.replace('\\\\s+No\\\\s+',False,regex=True)\n",
    "    combodf1 = combodf1.replace('\\\\s+No',False,regex=True)\n",
    "    combodf1 = combodf1.replace('No\\\\s+',False,regex=True)\n",
    "    #replace nans that were created by adding columns with 0s\n",
    "    combodf1 = combodf1.replace('nan','0')\n",
    "    #return the dataframe\n",
    "    return combodf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to be used to create non numeric columns\n",
    "#takes in a dataframe item\n",
    "#returns either that item or a string\n",
    "def add_non_numeric_cols(item):\n",
    "    #attempt to set type to decimal\n",
    "    try:\n",
    "        #if it was able to make a decimal return numeric\n",
    "        val = float(item)\n",
    "        return \"Numeric\"\n",
    "    except:\n",
    "        #otherwise return the string\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean column of non numeric data\n",
    "#takes in dataframe item\n",
    "#returns 0 or the decimal version of item.\n",
    "def change_to_dec(item):\n",
    "    #attemp to set type to decimal\n",
    "    try:\n",
    "        #if successful return item\n",
    "        val = float(item)\n",
    "        return val\n",
    "    except:\n",
    "        #otherwise return 0\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to bucket standardized enrollment\n",
    "#takes in dataframe item\n",
    "#returns bucket of the data\n",
    "def change_enrolled(item):\n",
    "    #first bucket\n",
    "    if item <.05:\n",
    "        return 0\n",
    "    #second bucket\n",
    "    elif item < .3:\n",
    "        return 1\n",
    "    #third bucket\n",
    "    elif item < .7:\n",
    "        return 2\n",
    "    #final bucket\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to add enrollment data to a dataframe\n",
    "#takes in a dataframe\n",
    "#returns dataframe combined with enrollment data\n",
    "def combine_enrollment(newdf1):\n",
    "    #read in enrollment data\n",
    "    enrollmentcsv = pd.read_excel(\"./Data/Enrollment.xlsx\")\n",
    "    #read in state population\n",
    "    statepop = pd.read_csv(\"./CSVs/StatePopulations.csv\")\n",
    "    #map state fips and abbreviation\n",
    "    abfips = us.states.mapping('fips','abbr')\n",
    "    #change mapping into dataframe\n",
    "    abfips = pd.DataFrame.from_dict([abfips])\n",
    "    abfips = abfips.transpose()\n",
    "    abfips = abfips.reset_index()\n",
    "    abfips = abfips.rename(columns={\"index\":\"fips\",0:\"abbr\"})\n",
    "    #merge enrollment and state info\n",
    "    enrollab = pd.merge(enrollmentcsv,abfips,left_on='State',right_on='abbr')\n",
    "    enrollab = enrollab.drop(columns=\"abbr\")\n",
    "    enrollab['fips'] = enrollab['fips'].astype(int)\n",
    "    #merge enrollement with state population\n",
    "    enrollabpop = pd.merge(enrollab,statepop,left_on=['fips','Year'],right_on=['state','Year'])\n",
    "    enrollabpop = enrollabpop.drop(columns=['state'])\n",
    "    #find average enrollment in a year\n",
    "    testgroup = pd.DataFrame(enrollabpop.groupby(['Contract Number','State','Year'])['Total Enrollments by State'].mean())\n",
    "    testgroup = testgroup.reset_index()\n",
    "    testgroup['Total Enrollments by State'] = testgroup['Total Enrollments by State'].round(0)\n",
    "    #rename columns\n",
    "    testgroup = testgroup.rename(columns={\"Total Enrollments by State\":\"Avg Enrollment\"})\n",
    "    #merge average enrollment into enrollment\n",
    "    enrollwavg = pd.merge(testgroup,enrollabpop,on=['Contract Number', 'State','Year'])\n",
    "    #standardize enrollment for state population\n",
    "    enrollwavg[\"Standardized Enrollment\"] = enrollwavg['Avg Enrollment']/enrollwavg['Population Over 65']\n",
    "    #remove unneccesary columns and drop duplicates that removing columns caused\n",
    "    enrollwavg1 = enrollwavg.copy()\n",
    "    enrollwavg1 = enrollwavg1.drop(columns=['Month','Total Enrollments by State'])\n",
    "    enrollwavg1 = enrollwavg1.drop_duplicates()\n",
    "    datatomerge = enrollwavg1.groupby([\"Contract Number\",\"Year\"])['Standardized Enrollment'].mean()\n",
    "    datatomerge = datatomerge.reset_index()\n",
    "    #merge enrollment data and star rating dataframe\n",
    "    finaldf = pd.merge(newdf1,datatomerge,on=['Contract Number','Year'])\n",
    "    #bucket the standardized enrollment data\n",
    "    finaldf[\"Standardized Enrollment\"] = finaldf[\"Standardized Enrollment\"].apply(change_enrolled)\n",
    "    #change enrollment column to int\n",
    "    finaldf[\"Standardized Enrollment\"] = finaldf[\"Standardized Enrollment\"].astype(int)\n",
    "    #return new dataframe\n",
    "    return finaldf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to split numeric and non-numeric columns\n",
    "#takes in a dataframe\n",
    "#returns a dataframe with numeric and non-numeric columns\n",
    "def split_numeric_nonnumeric_data(combodf4):\n",
    "    #get list of columns\n",
    "    cols = combodf4.keys().to_list()\n",
    "    cols.append(\"Overall\")\n",
    "    #loop through first five columns\n",
    "    for col in firstfive:\n",
    "        cols.remove(col)\n",
    "    #loop through last 2 columns\n",
    "    for col in lasttwo:\n",
    "        cols.remove(col)\n",
    "    #loops througy columns in dataframe\n",
    "    for col in cols:\n",
    "        #add non-numeric columns\n",
    "        combodf4[col+\" Non-numeric\"] = combodf4[col].apply(add_non_numeric_cols)\n",
    "        #change old columns to numeric\n",
    "        combodf4[col]=combodf4[col].apply(change_to_dec)\n",
    "    newcols = []#placeholder for new column order\n",
    "    #loop through columns\n",
    "    for col in cols:\n",
    "        #add numeric column\n",
    "        newcols.append(col)\n",
    "        #add non-numeric column\n",
    "        newcols.append(col+\" Non-numeric\")\n",
    "    finalcols =[]#placeholder for final column order\n",
    "    #add columns to final columns\n",
    "    for col in firstfive:\n",
    "        finalcols.append(col)\n",
    "    finalcols.append(\"Year\")\n",
    "    for col in newcols:\n",
    "        finalcols.append(col)\n",
    "    #change order of columns in dataframe\n",
    "    newdf1 = combodf4[finalcols]\n",
    "    return newdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combodf = standardize_data()\n",
    "combodf = clean_data(combodf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combodf = standardize_data()\n",
    "combodf.to_csv(\"./CSVs/CombinedData.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samsi\\AppData\\Local\\Temp\\ipykernel_37080\\2318447181.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  combodf1 = combodf1.replace('\\\\s*No\\\\s*',False,regex=True)\n"
     ]
    }
   ],
   "source": [
    "combodf = clean_data(combodf)\n",
    "combodf.to_csv(\"./CSVs/CombinedDataCleaned.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1=split_numeric_nonnumeric_data(combodf)\n",
    "newdf1.to_csv(\"./CSVs/CombinedDataNoEnrollment.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = combine_enrollment(newdf1)\n",
    "finaldf.to_csv(\"./CSVs/FinalData.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
